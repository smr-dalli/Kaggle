{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":44,"outputs":[{"output_type":"stream","text":"/kaggle/input/tabular-playground-series-mar-2021/sample_submission.csv\n/kaggle/input/tabular-playground-series-mar-2021/train.csv\n/kaggle/input/tabular-playground-series-mar-2021/test.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/train.csv')\ntrain.head()","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont2     cont3  \\\n0   0    A    I    A    B    B   BI    A    S    Q  ...  0.759439  0.795549   \n1   1    A    I    A    A    E   BI    K    W   AD  ...  0.386385  0.541366   \n2   2    A    K    A    A    E   BI    A    E   BM  ...  0.343255  0.616352   \n3   3    A    K    A    C    E   BI    A    Y   AD  ...  0.831147  0.807807   \n4   4    A    I    G    B    E   BI    C    G    Q  ...  0.338818  0.277308   \n\n      cont4     cont5     cont6     cont7     cont8     cont9    cont10 target  \n0  0.681917  0.621672  0.592184  0.791921  0.815254  0.965006  0.665915      0  \n1  0.388982  0.357778  0.600044  0.408701  0.399353  0.927406  0.493729      0  \n2  0.793687  0.552877  0.352113  0.388835  0.412303  0.292696  0.549452      0  \n3  0.800032  0.619147  0.221789  0.897617  0.633669  0.760318  0.934242      0  \n4  0.610578  0.128291  0.578764  0.279167  0.351103  0.357084  0.328960      1  \n\n[5 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>...</th>\n      <th>cont2</th>\n      <th>cont3</th>\n      <th>cont4</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>A</td>\n      <td>I</td>\n      <td>A</td>\n      <td>B</td>\n      <td>B</td>\n      <td>BI</td>\n      <td>A</td>\n      <td>S</td>\n      <td>Q</td>\n      <td>...</td>\n      <td>0.759439</td>\n      <td>0.795549</td>\n      <td>0.681917</td>\n      <td>0.621672</td>\n      <td>0.592184</td>\n      <td>0.791921</td>\n      <td>0.815254</td>\n      <td>0.965006</td>\n      <td>0.665915</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>A</td>\n      <td>I</td>\n      <td>A</td>\n      <td>A</td>\n      <td>E</td>\n      <td>BI</td>\n      <td>K</td>\n      <td>W</td>\n      <td>AD</td>\n      <td>...</td>\n      <td>0.386385</td>\n      <td>0.541366</td>\n      <td>0.388982</td>\n      <td>0.357778</td>\n      <td>0.600044</td>\n      <td>0.408701</td>\n      <td>0.399353</td>\n      <td>0.927406</td>\n      <td>0.493729</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>A</td>\n      <td>K</td>\n      <td>A</td>\n      <td>A</td>\n      <td>E</td>\n      <td>BI</td>\n      <td>A</td>\n      <td>E</td>\n      <td>BM</td>\n      <td>...</td>\n      <td>0.343255</td>\n      <td>0.616352</td>\n      <td>0.793687</td>\n      <td>0.552877</td>\n      <td>0.352113</td>\n      <td>0.388835</td>\n      <td>0.412303</td>\n      <td>0.292696</td>\n      <td>0.549452</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>A</td>\n      <td>K</td>\n      <td>A</td>\n      <td>C</td>\n      <td>E</td>\n      <td>BI</td>\n      <td>A</td>\n      <td>Y</td>\n      <td>AD</td>\n      <td>...</td>\n      <td>0.831147</td>\n      <td>0.807807</td>\n      <td>0.800032</td>\n      <td>0.619147</td>\n      <td>0.221789</td>\n      <td>0.897617</td>\n      <td>0.633669</td>\n      <td>0.760318</td>\n      <td>0.934242</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>A</td>\n      <td>I</td>\n      <td>G</td>\n      <td>B</td>\n      <td>E</td>\n      <td>BI</td>\n      <td>C</td>\n      <td>G</td>\n      <td>Q</td>\n      <td>...</td>\n      <td>0.338818</td>\n      <td>0.277308</td>\n      <td>0.610578</td>\n      <td>0.128291</td>\n      <td>0.578764</td>\n      <td>0.279167</td>\n      <td>0.351103</td>\n      <td>0.357084</td>\n      <td>0.328960</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Number of unique values in each categorical column\n\nunique_catcol_list = []\n\nfor i in range(19):\n    unique_val = train['cat'+str(i)].nunique()\n    unique_catcol_list.append('cat'+str(i)+':'+str(unique_val))\nprint(unique_catcol_list)","execution_count":46,"outputs":[{"output_type":"stream","text":"['cat0:2', 'cat1:15', 'cat2:19', 'cat3:13', 'cat4:20', 'cat5:84', 'cat6:16', 'cat7:51', 'cat8:61', 'cat9:19', 'cat10:299', 'cat11:2', 'cat12:2', 'cat13:2', 'cat14:2', 'cat15:4', 'cat16:4', 'cat17:4', 'cat18:4']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/test.csv')\ntest.head()","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont1     cont2  \\\n0   5    A    F    A    A    F   BI    A   AH   AX  ...  0.735690  0.578366   \n1   6    A    H    C    A    E   AB    I    F    N  ...  0.313703  0.928885   \n2   8    A    N    C    A    F   AB    A   AH   BC  ...  0.448201  0.424876   \n3   9    B    L    C    A    F   BI    A    E   AX  ...  0.666092  0.598943   \n4  11    A    F    A    B    F   BI    A   AH    I  ...  0.772229  0.479572   \n\n      cont3     cont4     cont5     cont6     cont7     cont8     cont9  \\\n0  0.723154  0.228037  0.356227  0.551249  0.655693  0.598331  0.359987   \n1  0.516602  0.600169  0.795224  0.248987  0.654614  0.347944  0.565520   \n2  0.344729  0.242073  0.270632  0.746740  0.335590  0.341238  0.252289   \n3  0.561971  0.806347  0.735983  0.538724  0.381566  0.481660  0.348514   \n4  0.767745  0.252454  0.354810  0.178920  0.763479  0.562491  0.466261   \n\n     cont10  \n0  0.947489  \n1  0.388580  \n2  0.411592  \n3  0.325723  \n4  0.585781  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>...</th>\n      <th>cont1</th>\n      <th>cont2</th>\n      <th>cont3</th>\n      <th>cont4</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>A</td>\n      <td>F</td>\n      <td>A</td>\n      <td>A</td>\n      <td>F</td>\n      <td>BI</td>\n      <td>A</td>\n      <td>AH</td>\n      <td>AX</td>\n      <td>...</td>\n      <td>0.735690</td>\n      <td>0.578366</td>\n      <td>0.723154</td>\n      <td>0.228037</td>\n      <td>0.356227</td>\n      <td>0.551249</td>\n      <td>0.655693</td>\n      <td>0.598331</td>\n      <td>0.359987</td>\n      <td>0.947489</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>A</td>\n      <td>H</td>\n      <td>C</td>\n      <td>A</td>\n      <td>E</td>\n      <td>AB</td>\n      <td>I</td>\n      <td>F</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0.313703</td>\n      <td>0.928885</td>\n      <td>0.516602</td>\n      <td>0.600169</td>\n      <td>0.795224</td>\n      <td>0.248987</td>\n      <td>0.654614</td>\n      <td>0.347944</td>\n      <td>0.565520</td>\n      <td>0.388580</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>A</td>\n      <td>N</td>\n      <td>C</td>\n      <td>A</td>\n      <td>F</td>\n      <td>AB</td>\n      <td>A</td>\n      <td>AH</td>\n      <td>BC</td>\n      <td>...</td>\n      <td>0.448201</td>\n      <td>0.424876</td>\n      <td>0.344729</td>\n      <td>0.242073</td>\n      <td>0.270632</td>\n      <td>0.746740</td>\n      <td>0.335590</td>\n      <td>0.341238</td>\n      <td>0.252289</td>\n      <td>0.411592</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>B</td>\n      <td>L</td>\n      <td>C</td>\n      <td>A</td>\n      <td>F</td>\n      <td>BI</td>\n      <td>A</td>\n      <td>E</td>\n      <td>AX</td>\n      <td>...</td>\n      <td>0.666092</td>\n      <td>0.598943</td>\n      <td>0.561971</td>\n      <td>0.806347</td>\n      <td>0.735983</td>\n      <td>0.538724</td>\n      <td>0.381566</td>\n      <td>0.481660</td>\n      <td>0.348514</td>\n      <td>0.325723</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>A</td>\n      <td>F</td>\n      <td>A</td>\n      <td>B</td>\n      <td>F</td>\n      <td>BI</td>\n      <td>A</td>\n      <td>AH</td>\n      <td>I</td>\n      <td>...</td>\n      <td>0.772229</td>\n      <td>0.479572</td>\n      <td>0.767745</td>\n      <td>0.252454</td>\n      <td>0.354810</td>\n      <td>0.178920</td>\n      <td>0.763479</td>\n      <td>0.562491</td>\n      <td>0.466261</td>\n      <td>0.585781</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns == train.drop('target',axis = 'columns').columns","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.isna().sum().sum())  ### No missing values in train data\nprint(test.isna().sum().sum())  ### No missing values in test data","execution_count":49,"outputs":[{"output_type":"stream","text":"0\n0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder,StandardScaler\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline\n","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Linear Model\n\nX = train.drop(['target','id'],axis = 'columns')\ny = train.target\ntest = test.drop('id',axis = 'columns')\n\n##Extracting categorical columns and numerical col list for preprocessing\ncat_col_list = X.select_dtypes(include = ['object']).columns.to_list()\nnum_col_list = X.select_dtypes(exclude = ['object']).columns.to_list()\n\npreprocessor = make_column_transformer((StandardScaler(),num_col_list),\n                                   (OneHotEncoder(handle_unknown = 'ignore'),cat_col_list))\n\nmodel = LinearRegression()\npipeline = make_pipeline(preprocessor,model)\npipeline.fit(X,y)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"Pipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('standardscaler',\n                                                  StandardScaler(),\n                                                  ['cont0', 'cont1', 'cont2',\n                                                   'cont3', 'cont4', 'cont5',\n                                                   'cont6', 'cont7', 'cont8',\n                                                   'cont9', 'cont10']),\n                                                 ('onehotencoder',\n                                                  OneHotEncoder(handle_unknown='ignore'),\n                                                  ['cat0', 'cat1', 'cat2',\n                                                   'cat3', 'cat4', 'cat5',\n                                                   'cat6', 'cat7', 'cat8',\n                                                   'cat9', 'cat10', 'cat11',\n                                                   'cat12', 'cat13', 'cat14',\n                                                   'cat15', 'cat16', 'cat17',\n                                                   'cat18'])])),\n                ('linearregression', LinearRegression())])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred = pipeline.predict(test)\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/test.csv')\ndf = pd.DataFrame()\ndf['id'] = test['id']\ndf['target'] = ypred\ndf.to_csv('sub.csv',index = False)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##XGBoost model\nimport xgboost\nfrom xgboost import XGBRegressor\nmodel = XGBRegressor()\npipeline = make_pipeline(preprocessor,model)\npipeline.fit(X,y)","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"Pipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('standardscaler',\n                                                  StandardScaler(),\n                                                  ['cont0', 'cont1', 'cont2',\n                                                   'cont3', 'cont4', 'cont5',\n                                                   'cont6', 'cont7', 'cont8',\n                                                   'cont9', 'cont10']),\n                                                 ('onehotencoder',\n                                                  OneHotEncoder(handle_unknown='ignore'),\n                                                  ['cat0', 'cat1', 'cat2',\n                                                   'cat3', 'cat4', 'cat5',\n                                                   'cat6', 'cat7', 'cat8',\n                                                   'cat9', 'cat10', 'cat11',\n                                                   'cat12', 'ca...\n                              colsample_bytree=1, gamma=0, gpu_id=-1,\n                              importance_type='gain',\n                              interaction_constraints='',\n                              learning_rate=0.300000012, max_delta_step=0,\n                              max_depth=6, min_child_weight=1, missing=nan,\n                              monotone_constraints='()', n_estimators=100,\n                              n_jobs=4, num_parallel_tree=1, random_state=0,\n                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n                              subsample=1, tree_method='exact',\n                              validate_parameters=1, verbosity=None))])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred1 = pipeline.predict(test.drop('id',axis = 'columns'))\ntest1 = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/test.csv')\ndf = pd.DataFrame()\ndf['id'] = test1['id']\ndf['target'] = ypred1\ndf.to_csv('sub_XGBR.csv',index = False)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['target','id'],axis = 'columns')\ny = train.target\ntest = test.drop('id',axis = 'columns')\n\n##Extracting categorical columns and numerical col list for preprocessing\ncat_col_list = X.select_dtypes(include = ['object']).columns.to_list()\nnum_col_list = X.select_dtypes(exclude = ['object']).columns.to_list()\n\npreprocessor = make_column_transformer((StandardScaler(),num_col_list),\n                                   (OneHotEncoder(sparse = False,handle_unknown = 'ignore'),cat_col_list))","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = preprocessor.fit_transform(X)\ntest = preprocessor.transform(test)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## NN using tensor flow\n\nmodel3 = Sequential([Dense(1024,activation = 'relu',input_shape = [X.shape[1]]),\n                     BatchNormalization(),\n                     Dropout(0.3),\n                     Dense(512, activation = 'relu'),\n                     BatchNormalization(),\n                     Dropout(0.3),\n                     Dense(256,activation = 'relu'),\n                     BatchNormalization(),\n                     Dropout(0.3),\n                     Dense(1)\n])\nmodel3.summary()","execution_count":56,"outputs":[{"output_type":"stream","text":"Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_16 (Dense)             (None, 1024)              650240    \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 1024)              4096      \n_________________________________________________________________\ndropout (Dropout)            (None, 1024)              0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 512)               524800    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 512)               2048      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_18 (Dense)             (None, 256)               131328    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 256)               1024      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_19 (Dense)             (None, 1)                 257       \n=================================================================\nTotal params: 1,313,793\nTrainable params: 1,310,209\nNon-trainable params: 3,584\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3.compile(loss = 'mae',optimizer = 'adam')\nmodel3.fit(X,y,batch_size = 256,epochs = 10)","execution_count":57,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n1172/1172 [==============================] - 40s 33ms/step - loss: 0.4089\nEpoch 2/10\n1172/1172 [==============================] - 39s 33ms/step - loss: 0.1836\nEpoch 3/10\n1172/1172 [==============================] - 40s 34ms/step - loss: 0.1759\nEpoch 4/10\n1172/1172 [==============================] - 41s 35ms/step - loss: 0.1708\nEpoch 5/10\n1172/1172 [==============================] - 42s 36ms/step - loss: 0.1687\nEpoch 6/10\n1172/1172 [==============================] - 40s 34ms/step - loss: 0.1657\nEpoch 7/10\n1172/1172 [==============================] - 39s 34ms/step - loss: 0.1653\nEpoch 8/10\n1172/1172 [==============================] - 40s 34ms/step - loss: 0.1631\nEpoch 9/10\n1172/1172 [==============================] - 39s 33ms/step - loss: 0.1633\nEpoch 10/10\n1172/1172 [==============================] - 39s 33ms/step - loss: 0.1606\n","name":"stdout"},{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f52ef4445d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred3 = model3.predict(test)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2 = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/test.csv')\ndf = pd.DataFrame()\ndf['id'] = test2['id']\ndf['target'] = ypred3\ndf.to_csv('sub_TF.csv',index = False)","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## NN using pytorch\nX = train.drop(['target','id'],axis = 'columns')\ny = train.target\ntest = test.drop('id',axis = 'columns')\n\n##Extracting categorical columns and numerical col list for preprocessing\ncat_col_list = X.select_dtypes(include = ['object']).columns.to_list()\nnum_col_list = X.select_dtypes(exclude = ['object']).columns.to_list()\n\npreprocessor = make_column_transformer((StandardScaler(),num_col_list),\n                                       (OneHotEncoder(sparse = False,handle_unknown = 'ignore'),cat_col_list))\n\nX = preprocessor.fit_transform(X)\ntest = preprocessor.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn\nfrom torch.nn import Linear\nfrom torch.nn import Dropout,BatchNorm1d","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model4 = nn.Sequential([nn.Linear(X.shape[1],500),\n                       nn.BatchNorm1d(500),\n                        nn.Dropout(0.3),\n                        nn.Linear(500,300),\n                        nn.BatchNorm1d(300),\n                        nn.Dropout(0.3),\n                        nn.Linear(100,1)\n                       \n                       ])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}